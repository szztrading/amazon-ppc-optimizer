# app.py â€” Amazon PPC Optimizerï¼ˆå«ä¸Šä¼ è¿›åº¦ã€æ—©æœŸå¦å®šæ‰«æã€è¯åº“å»ºè®®ï¼‰
import os, io, time, tempfile
import pandas as pd
import streamlit as st
from datetime import datetime

from ppc_optimizer_lib import load_config, calculate_metrics

st.set_page_config(page_title="Amazon PPC Optimizer", layout="wide")

st.title("ğŸ“Š Amazon å¹¿å‘Šä¼˜åŒ–å·¥å…·ï¼ˆå¸¦æ—©æœŸå¦å®š & è¯åº“å»ºè®®ï¼‰")
st.markdown("""
ğŸ“¥ **è¯·å…ˆä» Seller Central å¯¼å‡º Sponsored Products Â· Search Term Reportï¼ˆ30â€“60å¤©ï¼‰** åä¸Šä¼ ã€‚  
è¿è¡Œæµç¨‹ï¼š**æ¥æ”¶ â†’ è§£æ â†’ åˆ†æ â†’ å¯¼å‡º**ã€‚åœ¨æ•°æ®å¾ˆå°‘/æ— è½¬åŒ–æ—¶ï¼Œä¹Ÿä¼šç»™å‡º**æ—©æœŸå¦å®šè¯å»ºè®®**ä¸**è¯åº“æ›´æ–°å»ºè®®**ã€‚
""")

uploaded_file = st.file_uploader("ğŸ“¤ ä¸Šä¼  Search Term Reportï¼ˆCSV æˆ– XLSXï¼‰", type=["csv", "xlsx"])

if uploaded_file:
    st.caption(f"æ–‡ä»¶ï¼š**{uploaded_file.name}** | å¤§å°çº¦ **{len(uploaded_file.getbuffer())/1024/1024:.2f} MB**")

    with st.status("å‡†å¤‡å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶â€¦", state="running") as status:
        # â”€â”€ é˜¶æ®µ 1ï¼šæ¥æ”¶ï¼ˆå†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼Œæ¨¡æ‹Ÿç½‘ç»œè¿›åº¦ï¼‰ â”€â”€
        st.write("ğŸ“¦ æ­£åœ¨æ¥æ”¶æ–‡ä»¶ï¼ˆå†™å…¥æœåŠ¡å™¨ï¼‰â€¦")
        buf = uploaded_file.getbuffer()
        total = len(buf)
        recv_prog = st.progress(0, text="æ¥æ”¶è¿›åº¦ 0%")
        chunk = 1024 * 1024  # 1MB
        with tempfile.NamedTemporaryFile(delete=False) as tmp:
            tmp_path = tmp.name
            for i in range(0, total, chunk):
                end = min(i + chunk, total)
                tmp.write(buf[i:end])
                pct = int(end / total * 100) if total else 100
                recv_prog.progress(min(pct, 100), text=f"æ¥æ”¶è¿›åº¦ {pct}%")
                time.sleep(0.005)
        st.write("âœ… æ–‡ä»¶æ¥æ”¶å®Œæˆ")
        recv_prog.empty()

        # â”€â”€ é˜¶æ®µ 2ï¼šè§£æ â”€â”€
        st.write("ğŸ“– æ­£åœ¨è§£ææ–‡ä»¶ï¼ˆCSV/XLSXï¼‰â€¦")
        parse_prog = st.progress(0, text="å¼€å§‹è§£æâ€¦")
        try:
            if uploaded_file.name.lower().endswith(".csv"):
                df = pd.read_csv(tmp_path)
            else:
                df = pd.read_excel(tmp_path)
            parse_prog.progress(100, text="è§£æå®Œæˆ 100%")
            st.write("ğŸ” åŸå§‹åˆ—åï¼š", list(df.columns))
            st.write("ğŸ“Š æ•°æ®é¢„è§ˆï¼ˆå‰ 10 è¡Œï¼‰")
            st.dataframe(df.head(10))
        except Exception as e:
            parse_prog.empty()
            status.update(label=f"âŒ è§£æå¤±è´¥ï¼š{e}", state="error")
            st.stop()
        finally:
            try:
                os.remove(tmp_path)
            except Exception:
                pass

        # â”€â”€ é˜¶æ®µ 3ï¼šåˆ†æ â”€â”€
        st.write("ğŸ§  æ­£åœ¨åˆ†æï¼ˆè®¡ç®— CTR/CVR/ACOSï¼›åˆ†ç±»å»ºè®®ï¼›æ—©æœŸå¦å®šï¼›è¯åº“å»ºè®®ï¼‰â€¦")
        analyze_prog = st.progress(0, text="è½½å…¥é…ç½®â€¦")
        try:
            cfg = load_config()  # è¯»å– config.yaml
            analyze_prog.progress(30, text="æŒ‡æ ‡è®¡ç®— & è§„åˆ™åˆ†ç±»â€¦")
            results = calculate_metrics(df, cfg)
            analyze_prog.progress(100, text="åˆ†æå®Œæˆ")
            st.write("âœ… åˆ†æå®Œæˆ")
        except Exception as e:
            analyze_prog.empty()
            status.update(label=f"âŒ åˆ†æå¤±è´¥ï¼š{e}", state="error")
            st.stop()

        # â”€â”€ é˜¶æ®µ 4ï¼šå±•ç¤º & å¯¼å‡º â”€â”€
        today_str = datetime.now().strftime("%Y-%m-%d")

        st.subheader("ğŸ“ˆ æ±‡æ€»ä¸æ˜ç»†ï¼ˆAll_Termsï¼‰")
        st.dataframe(results["All_Terms"].head(300))

        col1, col2 = st.columns(2)
        with col1:
            st.subheader("ğŸŸ¢ Scale Upï¼ˆä½ ACOS & æœ‰è½¬åŒ–ï¼‰")
            st.dataframe(results["Scale_Up"].head(200))
            st.subheader("ğŸŸ¡ Bid Downï¼ˆé«˜ ACOS & ç‚¹å‡»è¶³å¤Ÿï¼‰")
            st.dataframe(results["Bid_Down"].head(200))
        with col2:
            st.subheader("âŒ Negativesï¼ˆç‚¹å‡»å¤šä¸”æ— å•ï¼‰")
            st.dataframe(results["Negatives"].head(200))
            st.subheader("ğŸŒ± Harvestï¼ˆé«˜è½¬åŒ–ç‡ï¼‰")
            st.dataframe(results["Harvest"].head(200))

        # æ—©æœŸå¦å®šï¼ˆä½æ•°æ®é‡ä¹Ÿèƒ½è¾“å‡ºå»ºè®®ï¼‰
        st.subheader("ğŸ§­ æ—©æœŸå¦å®šè¯ï¼ˆå«æ¥æºä¸ç†ç”±ï¼‰")
        st.caption("è¯´æ˜ï¼šå½“æ ·æœ¬å¾ˆå°‘/æ— è½¬åŒ–æ—¶ï¼ŒåŸºäºè¯æ ¹åº“è¯†åˆ«æ½œåœ¨æ— æ•ˆè¯ä¾›ä½ å®¡æ ¸ã€‚")
        st.dataframe(results["Early_Negatives_Source"].head(300))
        if not results["Early_Negatives_Source"].empty:
            src_csv = results["Early_Negatives_Source"].to_csv(index=False).encode("utf-8")
            st.download_button(
                f"â¬‡ï¸ ä¸‹è½½_å¦å®šè¯æ¥æºè¿½è¸ª_{today_str}.csv",
                src_csv,
                file_name=f"early_negatives_source_{today_str}.csv",
                mime="text/csv",
                use_container_width=True
            )

        st.subheader("ğŸ“¤ æ—©æœŸå¦å®šè¯ä¸Šä¼ è‰ç¨¿ï¼ˆnegative exactï¼‰")
        st.caption("å¯ç›´æ¥ç²˜è´´/ä¸Šä¼ åˆ°åå°ï¼›ä¹Ÿå¯æŒ‰æºæ´»åŠ¨å°±åœ°å¦å®šã€‚")
        st.dataframe(results["Early_Negatives_Upload"].head(300))
        if not results["Early_Negatives_Upload"].empty:
            up_csv = results["Early_Negatives_Upload"].to_csv(index=False).encode("utf-8")
            st.download_button(
                f"â¬‡ï¸ ä¸‹è½½_å¦å®šè¯ä¸Šä¼ è‰ç¨¿_{today_str}.csv",
                up_csv,
                file_name=f"early_negatives_upload_{today_str}.csv",
                mime="text/csv",
                use_container_width=True
            )

        # è¯åº“å»ºè®®
        st.subheader("ğŸ§© è¯åº“æ›´æ–°å»ºè®®ï¼ˆä½æ•°æ®é‡é€‚ç”¨ï¼‰")
        st.caption("ä»æ— è½¬åŒ–/ä½è´¨é‡æœç´¢è¯ä¸­æç‚¼é«˜é¢‘è¯æ ¹ï¼Œä¸æœ‰è½¬åŒ–è¯å¯¹æ¯”ï¼Œç»™å‡ºå»ºè®®ã€‚ADD_TO_PATTERNS å¯ç›´æ¥åŠ å…¥ config.yaml çš„ negatives_scan.patternsã€‚")
        lex = results["Lexicon_Suggestions"]
        st.dataframe(lex)
        if not lex.empty:
            csv = lex.to_csv(index=False).encode("utf-8")
            st.download_button(
                f"â¬‡ï¸ ä¸‹è½½_è¯åº“å»ºè®®_{today_str}.csv",
                csv, file_name=f"lexicon_suggestions_{today_str}.csv",
                mime="text/csv", use_container_width=True
            )
            add_list = lex.loc[lex["Recommendation"]=="ADD_TO_PATTERNS","Token"].tolist()
            if add_list:
                st.markdown("**ğŸ“‹ å»ºè®®åŠ å…¥åˆ° `negatives_scan.patterns.UNRELATED_CONTEXT`ï¼ˆç¤ºä¾‹ï¼‰**")
                yaml_block = "- " + "\n- ".join(add_list)
                st.code(yaml_block, language="yaml")
                st.caption("æŠŠä¸Šé¢åˆ—è¡¨ç²˜åˆ° config.yaml å¯¹åº”çš„ patterns åˆ†ç±»ä¸‹ï¼ˆæˆ–æŒ‰ä½ çš„åˆ†ç±»æ‹†åˆ†ï¼‰ã€‚")

        # æ€»å¯¼å‡ºï¼ˆExcel æ‰“åŒ…å„è¡¨ï¼‰
        st.write("ğŸ“¤ æ­£åœ¨å¯¼å‡º Excel â€¦")
        try:
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
                for name, df_out in results.items():
                    if isinstance(df_out, pd.DataFrame):
                        df_out.to_excel(writer, sheet_name=name[:31], index=False)
            st.download_button(
                "â¬‡ï¸ ä¸‹è½½ Excelï¼ˆå…¨éƒ¨ç»“æœï¼‰",
                data=output.getvalue(),
                file_name=f"ppc_output_{today_str}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True,
            )
            status.update(label="ğŸ‰ å…¨æµç¨‹å®Œæˆï¼šæ¥æ”¶ â†’ è§£æ â†’ åˆ†æ â†’ å¯¼å‡º", state="complete")
        except Exception as e:
            status.update(label=f"âŒ å¯¼å‡ºå¤±è´¥ï¼š{e}", state="error")
            st.stop()

else:
    st.info("ğŸ‘† è¯·ä¸Šä¼ æ–‡ä»¶åï¼Œç³»ç»Ÿä¼šæ˜¾ç¤ºå¤„ç†è¿›åº¦ã€‚")
