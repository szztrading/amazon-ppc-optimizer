# app.py â€” Amazon PPC Optimizerï¼ˆå«ä¸Šä¼ è¿›åº¦ã€æ—©æœŸå¦å®šæ‰«æã€è¯åº“å»ºè®® + v1.1 æä»·âæ‹†è¯/SKAG/å¦å®šå¯¼å‡ºï¼Œå¦å®šè¯æ ¹ä» config.yaml è¯»å–ï¼‰
import os, io, time, tempfile
import pandas as pd
import streamlit as st
from datetime import datetime

from ppc_optimizer_lib import load_config, calculate_metrics  # ä½ å·²æœ‰çš„åº“ï¼šè¯»å– config.yaml & ä¸»åˆ†æ

st.set_page_config(page_title="Amazon PPC Optimizer", layout="wide")

# =========================
# v1.1 æ–°å¢ï¼šå…±ç”¨å°å·¥å…·
# =========================
def _safe_div(a, b):
    try:
        return (a / b) if b else 0.0
    except Exception:
        return 0.0

def _standardize_columns(df):
    """
    å°†å¸¸è§çš„åˆ—åæ˜ å°„æˆæ ‡å‡†åˆ—ï¼Œä¾¿äºç»Ÿä¸€è®¡ç®—ã€‚
    æœ‰åˆ™æ˜ å°„ï¼Œæ— åˆ™å¿½ç•¥ï¼ˆä¿æŒé²æ£’ï¼‰ã€‚
    """
    rename_map = {
        # æœç´¢è¯
        "Customer Search Term": "search_term",
        "customer_search_term": "search_term",
        "Search Term": "search_term",
        "Query": "search_term",
        # æŒ‡æ ‡
        "Clicks": "clicks",
        "Impressions": "impressions",
        "Spend": "spend",
        "Cost": "spend",
        "7 Day Total Sales": "sales",
        "Sales": "sales",
        "7 Day Total Orders (#)": "orders",
        "Orders": "orders",
        # ç»“æ„
        "Campaign Name": "campaign",
        "Ad Group Name": "ad_group",
    }
    for k, v in rename_map.items():
        if k in df.columns and v not in df.columns:
            df = df.rename(columns={k: v})
    return df

def _ensure_metrics(df):
    """
    ç¡®ä¿ df å…·å¤‡ ctr / cpc / acos / cvr æŒ‡æ ‡ï¼›è‹¥ç¼ºå¤±åˆ™è®¡ç®—ã€‚
    """
    df = df.copy()
    df = _standardize_columns(df)
    for col in ["clicks", "impressions", "spend", "sales", "orders"]:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0)
    if "ctr" not in df.columns and {"clicks","impressions"}.issubset(df.columns):
        df["ctr"] = df.apply(lambda r: _safe_div(r["clicks"], r["impressions"]), axis=1)
    if "cpc" not in df.columns and {"spend","clicks"}.issubset(df.columns):
        df["cpc"] = df.apply(lambda r: _safe_div(r["spend"], r["clicks"]), axis=1)
    if "acos" not in df.columns and {"spend","sales"}.issubset(df.columns):
        df["acos"] = df.apply(lambda r: _safe_div(r["spend"], r["sales"]), axis=1)
    if "cvr" not in df.columns and {"orders","clicks"}.issubset(df.columns):
        df["cvr"] = df.apply(lambda r: _safe_div(r["orders"], r["clicks"]), axis=1)
    return df

def _build_v11_decision_tables(df_all_terms, cfg, target_acos=0.30, min_clicks=20, min_orders=2):
    """
    ä¾æ®è§„åˆ™ç”Ÿæˆï¼šé»„é‡‘è¯ï¼ˆæ‹†è¯å»ºExactï¼‰ã€ç»§ç»­æµ‹è¯•ã€é™ä»·/å¦å®šï¼Œ
    å¹¶äº§å‡º SKAG å»ºç»„å»ºè®®ã€å¦å®šæ¸…å•ï¼ˆExact / Phrase Roots ä» config.yamlï¼‰
    """
    df = _ensure_metrics(df_all_terms)

    # å†³ç­–æ ‡ç­¾
    cond_pass = (df["clicks"] >= min_clicks) & (df["orders"] >= min_orders) & (df["acos"] <= target_acos)
    cond_test = (df["clicks"] >= min_clicks) & (
        (df["orders"] < min_orders) | ((df["acos"] > target_acos) & (df["acos"] <= target_acos + 0.10))
    )
    cond_fail = (df["clicks"] >= min_clicks) & (df["orders"] < min_orders) & (df["acos"] > target_acos + 0.10)

    df_dec = df.copy()
    df_dec["decision"] = pd.Series("æ ·æœ¬ä¸è¶³", index=df_dec.index)
    df_dec.loc[cond_pass, "decision"] = "æ‹†è¯å»ºExact"
    df_dec.loc[cond_test, "decision"] = "ç»§ç»­æµ‹è¯•"
    df_dec.loc[cond_fail, "decision"] = "é™ä»·/å¦å®š"

    df_pass = df_dec[df_dec["decision"]=="æ‹†è¯å»ºExact"].sort_values(["acos","clicks"], ascending=[True, False])
    df_test = df_dec[df_dec["decision"]=="ç»§ç»­æµ‹è¯•"].sort_values(["clicks"], ascending=False)
    df_fail = df_dec[df_dec["decision"]=="é™ä»·/å¦å®š"].sort_values(["acos","clicks"], ascending=[False, False])

    # SKAG å»ºç»„å»ºè®®è¡¨ï¼ˆExact å•è¯ç»„ï¼‰
    rows = []
    for _, r in df_pass.iterrows():
        kw = str(r.get("search_term","")).strip()
        base_cpc = r.get("cpc", 0.3) or 0.3
        start_bid = max(0.05, round(base_cpc * 1.00, 2))  # åˆå§‹å‡ºä»· = æœ€è¿‘æœŸå¹³å‡CPC * 1.0
        rows.append({
            "Campaign Name": "Exact - SKAG - Core",
            "Ad Group Name": f"Exact - {kw[:70]}",
            "Match Type": "Exact",
            "Keyword": kw,
            "Start Bid": start_bid,
            "Top of Search Adj": "30%~50%",   # å¢é•¿å‹Â·ä¸­ç­‰æ¡£
            "Reason": "é»„é‡‘è¯æ‹†åˆ†ï¼Œç‹¬ç«‹å†²é‡"
        })
    df_skag = pd.DataFrame(rows)

    # å¦å®šï¼šç‚¹å‡»â‰¥min_clicks ä¸” æ— å• æˆ– ACOS>50%
    neg_exact = df_dec[
        (df_dec["clicks"] >= min_clicks) & ((df_dec["orders"] == 0) | (df_dec["acos"] > 0.50))
    ].copy()
    neg_exact = neg_exact.rename(columns={"search_term":"Negative Term"})
    if "Negative Term" in neg_exact.columns:
        neg_exact["Match Type"] = "Negative Exact"
    neg_exact = neg_exact[["Negative Term","clicks","orders","spend","sales","acos","Match Type"]]

    # â¬‡ï¸ ä» config.yaml è¯»å–å¦å®šè¯æ ¹
    phrase_roots = []
    try:
        phrase_roots = cfg.get("negatives_scan", {}).get("phrase_roots", [])
    except Exception:
        pass
    df_neg_phrase_roots = pd.DataFrame({"Negative Phrase Root": phrase_roots})

    return df_dec, df_pass, df_test, df_fail, df_skag, neg_exact, df_neg_phrase_roots

def _export_v11_excel(df_all, df_pass, df_test, df_fail, df_skag, df_neg_exact, df_neg_phrase):
    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine="xlsxwriter") as writer:
        df_all.to_excel(writer, sheet_name="All_Analyzed", index=False)
        df_pass.to_excel(writer, sheet_name="To_Exact_Split", index=False)
        df_test.to_excel(writer, sheet_name="Keep_Testing", index=False)
        df_fail.to_excel(writer, sheet_name="BidDown_or_Neg", index=False)
        df_skag.to_excel(writer, sheet_name="SKAG_Plan", index=False)
        df_neg_exact.to_excel(writer, sheet_name="Neg_Exact", index=False)
        df_neg_phrase.to_excel(writer, sheet_name="Neg_Phrase_Roots", index=False)
    buffer.seek(0)
    return buffer


# =========================
# é¡µé¢å¼€å§‹ï¼ˆä¿ç•™ä½ åŸæœ‰çš„å†…å®¹ï¼‰
# =========================
st.title("ğŸ“Š SZZ Amazon å¹¿å‘Šä¼˜åŒ–å·¥å…·ï¼ˆæ—©æœŸå¦å®š & è¯åº“å»ºè®® + v1.1 è¡ŒåŠ¨è¡¨ï¼‰")
st.markdown("""
ğŸ“¥ **è¯·å…ˆä» Seller Central å¯¼å‡º Sponsored Products Â· Search Term Reportï¼ˆ30â€“60å¤©ï¼‰** åä¸Šä¼ ã€‚  
è¿è¡Œæµç¨‹ï¼š**æ¥æ”¶ â†’ è§£æ â†’ åˆ†æ â†’ å¯¼å‡º**ã€‚åœ¨æ•°æ®å¾ˆå°‘/æ— è½¬åŒ–æ—¶ï¼Œä¹Ÿä¼šç»™å‡º**æ—©æœŸå¦å®šè¯å»ºè®®**ä¸**è¯åº“æ›´æ–°å»ºè®®**ã€‚  
ğŸ†• v1.1ï¼šæ–°å¢ **â€œæä»· â æ‹†è¯ï¼ˆä¸“ä¸šç‰ˆï¼‰/ SKAG å»ºç»„ / å¦å®šæ¸…å• / ä¸€é”®å¯¼å‡ºâ€**ï¼ˆå¦å®šè¯æ ¹ä» `config.yaml` è¯»å–ï¼‰ã€‚
""")

uploaded_file = st.file_uploader("ğŸ“¤ ä¸Šä¼  Search Term Reportï¼ˆCSV æˆ– XLSXï¼‰", type=["csv", "xlsx"])

if uploaded_file:
    st.caption(f"æ–‡ä»¶ï¼š**{uploaded_file.name}** | å¤§å°çº¦ **{len(uploaded_file.getbuffer())/1024/1024:.2f} MB**")

    with st.status("å‡†å¤‡å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶â€¦", state="running") as status:
        # â”€â”€ é˜¶æ®µ 1ï¼šæ¥æ”¶ï¼ˆå†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼Œå¸¦è¿›åº¦æ¡ï¼‰ â”€â”€
        st.write("ğŸ“¦ æ­£åœ¨æ¥æ”¶æ–‡ä»¶ï¼ˆå†™å…¥æœåŠ¡å™¨ï¼‰â€¦")
        buf = uploaded_file.getbuffer()
        total = len(buf)
        recv_prog = st.progress(0, text="æ¥æ”¶è¿›åº¦ 0%")
        chunk = 1024 * 1024  # 1MB
        with tempfile.NamedTemporaryFile(delete=False) as tmp:
            tmp_path = tmp.name
            for i in range(0, total, chunk):
                end = min(i + chunk, total)
                tmp.write(buf[i:end])
                pct = int(end / total * 100) if total else 100
                recv_prog.progress(min(pct, 100), text=f"æ¥æ”¶è¿›åº¦ {pct}%")
                time.sleep(0.005)
        st.write("âœ… æ–‡ä»¶æ¥æ”¶å®Œæˆ")
        recv_prog.empty()

        # â”€â”€ é˜¶æ®µ 2ï¼šè§£æ â”€â”€
        st.write("ğŸ“– æ­£åœ¨è§£ææ–‡ä»¶ï¼ˆCSV/XLSXï¼‰â€¦")
        parse_prog = st.progress(0, text="å¼€å§‹è§£æâ€¦")
        try:
            if uploaded_file.name.lower().endswith(".csv"):
                df = pd.read_csv(tmp_path)
            else:
                df = pd.read_excel(tmp_path)
            parse_prog.progress(100, text="è§£æå®Œæˆ 100%")
            st.write("ğŸ” åŸå§‹åˆ—åï¼š", list(df.columns))
            st.write("ğŸ“Š æ•°æ®é¢„è§ˆï¼ˆå‰ 10 è¡Œï¼‰")
            st.dataframe(df.head(10))
        except Exception as e:
            parse_prog.empty()
            status.update(label=f"âŒ è§£æå¤±è´¥ï¼š{e}", state="error")
            st.stop()
        finally:
            try:
                os.remove(tmp_path)
            except Exception:
                pass

        # â”€â”€ é˜¶æ®µ 3ï¼šåˆ†æï¼ˆæ²¿ç”¨ä½ åŸæœ‰ calculate_metricsï¼‰ â”€â”€
        st.write("ğŸ§  æ­£åœ¨åˆ†æï¼ˆè®¡ç®— CTR/CVR/ACOSï¼›åˆ†ç±»å»ºè®®ï¼›æ—©æœŸå¦å®šï¼›è¯åº“å»ºè®®ï¼‰â€¦")
        analyze_prog = st.progress(0, text="è½½å…¥é…ç½®â€¦")
        try:
            cfg = load_config()  # è¯»å– config.yaml
            analyze_prog.progress(30, text="æŒ‡æ ‡è®¡ç®— & è§„åˆ™åˆ†ç±»â€¦")
            results = calculate_metrics(df, cfg)
            analyze_prog.progress(100, text="åˆ†æå®Œæˆ")
            st.write("âœ… åˆ†æå®Œæˆ")
        except Exception as e:
            analyze_prog.empty()
            status.update(label=f"âŒ åˆ†æå¤±è´¥ï¼š{e}", state="error")
            st.stop()

        # â”€â”€ é˜¶æ®µ 4ï¼šå±•ç¤ºä½ åŸæœ‰çš„è¾“å‡º â”€â”€
        today_str = datetime.now().strftime("%Y-%m-%d")

        st.subheader("ğŸ“ˆ æ±‡æ€»ä¸æ˜ç»†ï¼ˆAll_Termsï¼‰")
        st.dataframe(results["All_Terms"].head(300))

        col1, col2 = st.columns(2)
        with col1:
            st.subheader("ğŸŸ¢ Scale Upï¼ˆä½ ACOS & æœ‰è½¬åŒ–ï¼‰")
            st.dataframe(results["Scale_Up"].head(200))
            st.subheader("ğŸŸ¡ Bid Downï¼ˆé«˜ ACOS & ç‚¹å‡»è¶³å¤Ÿï¼‰")
            st.dataframe(results["Bid_Down"].head(200))
        with col2:
            st.subheader("âŒ Negativesï¼ˆç‚¹å‡»å¤šä¸”æ— å•ï¼‰")
            st.dataframe(results["Negatives"].head(200))
            st.subheader("ğŸŒ± Harvestï¼ˆé«˜è½¬åŒ–ç‡ï¼‰")
            st.dataframe(results["Harvest"].head(200))

        # æ—©æœŸå¦å®šï¼ˆä½æ•°æ®é‡ä¹Ÿèƒ½è¾“å‡ºå»ºè®®ï¼‰
        st.subheader("ğŸ§­ æ—©æœŸå¦å®šè¯ï¼ˆå«æ¥æºä¸ç†ç”±ï¼‰")
        st.caption("è¯´æ˜ï¼šå½“æ ·æœ¬å¾ˆå°‘/æ— è½¬åŒ–æ—¶ï¼ŒåŸºäºè¯æ ¹åº“è¯†åˆ«æ½œåœ¨æ— æ•ˆè¯ä¾›ä½ å®¡æ ¸ã€‚")
        st.dataframe(results["Early_Negatives_Source"].head(300))
        if not results["Early_Negatives_Source"].empty:
            src_csv = results["Early_Negatives_Source"].to_csv(index=False).encode("utf-8")
            st.download_button(
                f"â¬‡ï¸ ä¸‹è½½_å¦å®šè¯æ¥æºè¿½è¸ª_{today_str}.csv",
                src_csv,
                file_name=f"early_negatives_source_{today_str}.csv",
                mime="text/csv",
                use_container_width=True
            )

        st.subheader("ğŸ“¤ æ—©æœŸå¦å®šè¯ä¸Šä¼ è‰ç¨¿ï¼ˆnegative exactï¼‰")
        st.caption("å¯ç›´æ¥ç²˜è´´/ä¸Šä¼ åˆ°åå°ï¼›ä¹Ÿå¯æŒ‰æºæ´»åŠ¨å°±åœ°å¦å®šã€‚")
        st.dataframe(results["Early_Negatives_Upload"].head(300))
        if not results["Early_Negatives_Upload"].empty:
            up_csv = results["Early_Negatives_Upload"].to_csv(index=False).encode("utf-8")
            st.download_button(
                f"â¬‡ï¸ ä¸‹è½½_å¦å®šè¯ä¸Šä¼ è‰ç¨¿_{today_str}.csv",
                up_csv,
                file_name=f"early_negatives_upload_{today_str}.csv",
                mime="text/csv",
                use_container_width=True
            )

        # è¯åº“å»ºè®®
        st.subheader("ğŸ§© è¯åº“æ›´æ–°å»ºè®®ï¼ˆä½æ•°æ®é‡é€‚ç”¨ï¼‰")
        st.caption("ä»æ— è½¬åŒ–/ä½è´¨é‡æœç´¢è¯ä¸­æç‚¼é«˜é¢‘è¯æ ¹ï¼Œä¸æœ‰è½¬åŒ–è¯å¯¹æ¯”ï¼Œç»™å‡ºå»ºè®®ã€‚ADD_TO_PATTERNS å¯ç›´æ¥åŠ å…¥ config.yaml çš„ negatives_scan.patternsã€‚")
        lex = results["Lexicon_Suggestions"]
        st.dataframe(lex)
        if not lex.empty:
            csv = lex.to_csv(index=False).encode("utf-8")
            st.download_button(
                f"â¬‡ï¸ ä¸‹è½½_è¯åº“å»ºè®®_{today_str}.csv",
                csv, file_name=f"lexicon_suggestions_{today_str}.csv",
                mime="text/csv", use_container_width=True
            )
            add_list = lex.loc[lex["Recommendation"]=="ADD_TO_PATTERNS","Token"].tolist()
            if add_list:
                st.markdown("**ğŸ“‹ å»ºè®®åŠ å…¥åˆ° `negatives_scan.patterns.UNRELATED_CONTEXT`ï¼ˆç¤ºä¾‹ï¼‰**")
                yaml_block = "- " + "\n- ".join(add_list)
                st.code(yaml_block, language="yaml")
                st.caption("æŠŠä¸Šé¢åˆ—è¡¨ç²˜åˆ° config.yaml å¯¹åº”çš„ patterns åˆ†ç±»ä¸‹ï¼ˆæˆ–æŒ‰ä½ çš„åˆ†ç±»æ‹†åˆ†ï¼‰ã€‚")

        # =========================
        # v1.1 æ–°å¢é¢æ¿ï¼šæä»· â æ‹†è¯ / SKAG / å¦å®š / ä¸€é”®å¯¼å‡º
        # =========================
        st.markdown("---")
        st.header("ğŸ“ˆ v1.1 æä»· â æ‹†è¯ï¼ˆä¸“ä¸šç‰ˆï¼‰ Â· SKAG å»ºç»„ Â· å¦å®šæ¸…å• Â· å¯¼å‡º")
        st.caption("æ ¹æ®ç›®æ ‡ ACOSã€æœ€å°‘ç‚¹å‡»ã€æœ€å°‘è®¢å•ï¼Œè‡ªåŠ¨åˆ¤å®šé»„é‡‘è¯/ç»§ç»­æµ‹è¯•/é™ä»·å¦å®šï¼Œå¹¶ç”Ÿæˆ SKAG å»ºç»„ä¸å¦å®šè¯æ¸…å•ï¼ˆå¦å®šè¯æ ¹æ¥è‡ª config.yamlï¼‰ã€‚")

        with st.expander("âš™ï¸ åˆ¤å®šé˜ˆå€¼ï¼ˆå¯è°ƒæ•´ï¼‰", expanded=False):
            target_acos = st.slider("ğŸ¯ ç›®æ ‡ ACOS", 0.10, 0.60, 0.30, 0.01)
            min_clicks  = st.number_input("ğŸ” æœ€å°‘ç‚¹å‡»ï¼ˆè¿›å…¥åˆ¤æ–­ï¼‰", 5, 200, 20, 1)
            min_orders  = st.number_input("ğŸ“¦ æœ€å°‘è®¢å•ï¼ˆé»„é‡‘è¯é—¨æ§›ï¼‰", 1, 10, 2, 1)

        # ä½¿ç”¨ä½  pipeline çš„ All_Terms ä½œä¸ºåŸºç¡€ï¼ˆè‹¥æ²¡æœ‰åˆ™å›é€€ç”¨åŸ dfï¼‰
        base_df_for_v11 = results.get("All_Terms", df)
        df_all, df_pass, df_test, df_fail, df_skag, df_neg_exact, df_neg_phrase = _build_v11_decision_tables(
            base_df_for_v11, cfg, target_acos=target_acos, min_clicks=min_clicks, min_orders=min_orders
        )

        st.success(f"åˆ†æç»“æœï¼šâœ… æ‹†è¯å»ºExact {len(df_pass)} æ¡ ï½œ âš ï¸ ç»§ç»­æµ‹è¯• {len(df_test)} æ¡ ï½œ âŒ é™ä»·/å¦å®š {len(df_fail)} æ¡")

        st.subheader("âœ… æ‹†è¯å»º Exactï¼ˆé»„é‡‘è¯ï¼‰")
        cols_show = ["search_term","clicks","orders","spend","sales","acos","cpc","cvr"]
        if "campaign" in df_pass.columns: cols_show += ["campaign","ad_group"]
        st.dataframe(df_pass[cols_show], use_container_width=True)

        st.subheader("ğŸ§© SKAG å»ºç»„å»ºè®®ï¼ˆExact å•è¯ç»„ï¼‰")
        st.dataframe(df_skag, use_container_width=True)

        st.subheader("âŒ å¦å®šè¯å€™é€‰ï¼ˆNegative Exactï¼‰")
        st.dataframe(df_neg_exact, use_container_width=True)

        st.subheader("ğŸ§± è¯æ ¹å¦å®šï¼ˆNegative Phrase Roots / æ¥è‡ª config.yamlï¼‰")
        st.dataframe(df_neg_phrase, use_container_width=True)

        # â€”â€” v1.1 ä¸“ç”¨å¯¼å‡º â€”â€” #
        today_compact = datetime.now().strftime("%Y%m%d")
        v11_excel = _export_v11_excel(df_all, df_pass, df_test, df_fail, df_skag, df_neg_exact, df_neg_phrase)
        st.download_button(
            label=f"ğŸ“¥ ä¸‹è½½ï¼šppc_actions_{today_compact}.xlsx",
            data=v11_excel,
            file_name=f"ppc_actions_{today_compact}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True
        )
        st.download_button(
            "ğŸ“¥ ä¸‹è½½ï¼šskag_plan.csv",
            data=df_skag.to_csv(index=False).encode("utf-8-sig"),
            file_name=f"skag_plan_{today_compact}.csv",
            mime="text/csv",
            use_container_width=True
        )
        st.download_button(
            "ğŸ“¥ ä¸‹è½½ï¼šnegatives_exact.csv",
            data=df_neg_exact.to_csv(index=False).encode("utf-8-sig"),
            file_name=f"negatives_exact_{today_compact}.csv",
            mime="text/csv",
            use_container_width=True
        )
        st.download_button(
            "ğŸ“¥ ä¸‹è½½ï¼šnegatives_phrase_roots.csv",
            data=df_neg_phrase.to_csv(index=False).encode("utf-8-sig"),
            file_name=f"negatives_phrase_roots_{today_compact}.csv",
            mime="text/csv",
            use_container_width=True
        )

        # â”€â”€ é˜¶æ®µ 5ï¼šä½ çš„â€œæ€»å¯¼å‡ºâ€ï¼ˆåŸæœ‰é€»è¾‘ä¿ç•™ï¼‰ â”€â”€
        st.markdown("---")
        st.write("ğŸ“¤ æ­£åœ¨å¯¼å‡º Excelï¼ˆå…¨éƒ¨ç»“æœåˆé›†ï¼‰ â€¦")
        try:
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
                for name, df_out in results.items():
                    if isinstance(df_out, pd.DataFrame):
                        df_out.to_excel(writer, sheet_name=name[:31], index=False)
            st.download_button(
                "â¬‡ï¸ ä¸‹è½½ Excelï¼ˆå…¨éƒ¨ç»“æœï¼‰",
                data=output.getvalue(),
                file_name=f"ppc_output_{today_str}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True,
            )
            status.update(label="ğŸ‰ å…¨æµç¨‹å®Œæˆï¼šæ¥æ”¶ â†’ è§£æ â†’ åˆ†æ â†’ å¯¼å‡º", state="complete")
        except Exception as e:
            status.update(label=f"âŒ å¯¼å‡ºå¤±è´¥ï¼š{e}", state="error")
            st.stop()

else:
    st.info("ğŸ‘† è¯·ä¸Šä¼ æ–‡ä»¶åï¼Œç³»ç»Ÿä¼šæ˜¾ç¤ºå¤„ç†è¿›åº¦ã€‚")
